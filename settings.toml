[oobabooga_api]
use_streaming = true
blocking_url = 'http://192.168.1.20:5000/api/v1/generate'
streaming_url = 'ws://192.168.1.20:5005/api/v1/stream'
# preset_name should be a oobabooga preset; None will use the defaults hardcoded into library/ai_requests.py
preset_name = 'None'
context_length = 8192

[prompt_gen]
#prompt_file_path = "processors/few_shot_templates/full_prompt.txt"
prompt_file_path = "user/few_shot_templates/full_prompt.txt"
# continuation_likelyhood: "continuation" lets you split the story into two parts, a "context" and a "continuation".
#   Then, you would generate a prompt for the "continuation" and train on "context + prompt" -> "continuation".
#   The idea is to prevent ignoring previous parts of the story.
continuation_likelyhood = 0.5

[prompt_format]
# json_key_order: Pretty print order of the json files; unexpected keys will be at the end.
json_key_order = ["prompt", "tone", "writing style", "pacing", "point of view", "moment-to-moment detail",
  "sensory detail", "male characters", "female characters", "context", "story"]
# allowed_fields: The fields that are preserved when the prompt jsons are converted into the dataset jsons.
allowed_fields = ["prompt", "tone", "writing style", "pacing", "point of view", "moment-to-moment detail",
  "sensory detail", "context", "story", "system suffix"]
# tag_drop_rate: The rate that a tag is left out of prompt in the final dataset.
#   The idea is that the less tags there are, the stronger the influence training has on them.
tag_drop_rate = 0.5
# droppable_tags: Tags that will be influenced by the tag_drop_rate.
droppable_tags = ['tone', 'writing style', 'pacing', 'sensory detail']
# validation_set_size: the % of prompts to go to the validation set instead of the main dataset. 0.0 to 1.0.
validation_set_size = 0.0

[randomize_names]
keys_containing_names = ["prompt", "humorous elements", "point of view", "male characters", "female characters",
  "context", "story"]
randomization_blacklist = ["The", "N/A", "Unnamed", "Death", "Man", "Woman", "Child", "Saint", "Teacher"]

[hacks]
# enables tweaks for my particular dataset
undo_hyphens_in_prompt = true
redistribute_authors = true
swap_tag_values = true
use_prose_styles = true
